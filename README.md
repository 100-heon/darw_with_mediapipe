# Overview
This project uses Mediapipe and PyTorch to build a hand gesture recognition model. It includes code for both model training and real-time gesture prediction. The program can recognize specific hand gestures and display them live on the screen.
<img width="474" alt="스크린샷 2024-11-04 오후 5 19 25" src="https://github.com/user-attachments/assets/a4424ad7-b59e-46dd-8af3-eb2467164f72">


install Anaconda: (recommended)

Download Anaconda from the link above.
Follow the installation instructions.
Once installed, open the terminal (or Anaconda Prompt on Windows) to create a new environment:
```
conda create -n hand-gesture-env python=3.9
conda activate hand-gesture-env
```
Note: If you have not installed Anaconda, you can ignore any steps that include conda.

## Step-by-Step Setup
1. Clone the Repository
First, open a terminal. To navigate to your desired directory, type:

```
git clone https://github.com/yourusername/hand-gesture-recognition.git
```

```
cd hand-gesture-recognition
```


## Install Required Packages
```
pip install -r requirements.txt
```

## run
```
python detect.py
```
